{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f695bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b543836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50a535d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08eea1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('1706.03762v7.pdf')\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2d4ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "text_splitter = NLTKTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eafcdaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_documents = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5005f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dccac22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Milvus\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\"uri\": \"https://in03-945f9d7d1a53526.serverless.aws-eu-central-1.cloud.zilliz.com\", \"token\": os.getenv(\"MILVUS_API_KEY\")},\n",
    "    index_params={\"index_type\": \"FLAT\", \"metric_type\": \"L2\"},\n",
    "    auto_id=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee3f1960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.milvus.Milvus at 0x1abdea667d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90d328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[459601663938464653,\n",
       " 459601663938464654,\n",
       " 459601663938464655,\n",
       " 459601663938464656,\n",
       " 459601663938464657,\n",
       " 459601663938464658,\n",
       " 459601663938464659,\n",
       " 459601663938464660,\n",
       " 459601663938464661,\n",
       " 459601663938464662,\n",
       " 459601663938464663,\n",
       " 459601663938464664,\n",
       " 459601663938464665,\n",
       " 459601663938464666,\n",
       " 459601663938464667,\n",
       " 459601663938464668,\n",
       " 459601663938464669,\n",
       " 459601663938464670,\n",
       " 459601663938464671,\n",
       " 459601663938464672,\n",
       " 459601663938464673,\n",
       " 459601663938464674,\n",
       " 459601663938464675,\n",
       " 459601663938464676,\n",
       " 459601663938464677,\n",
       " 459601663938464678,\n",
       " 459601663938464679,\n",
       " 459601663938464680,\n",
       " 459601663938464681,\n",
       " 459601663938464682,\n",
       " 459601663938464683,\n",
       " 459601663938464684,\n",
       " 459601663938464685,\n",
       " 459601663938464686,\n",
       " 459601663938464687,\n",
       " 459601663938464688,\n",
       " 459601663938464689,\n",
       " 459601663938464690,\n",
       " 459601663938464691,\n",
       " 459601663938464692,\n",
       " 459601663938464693,\n",
       " 459601663938464694,\n",
       " 459601663938464695,\n",
       " 459601663938464696,\n",
       " 459601663938464697,\n",
       " 459601663938464698,\n",
       " 459601663938464699,\n",
       " 459601663938464700,\n",
       " 459601663938464701,\n",
       " 459601663938464702,\n",
       " 459601663938464703,\n",
       " 459601663938464704,\n",
       " 459601663938464705]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "# 1. Load PDF\n",
    "loader = PyPDFLoader(\"1706.03762v7.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Split\n",
    "text_splitter = NLTKTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Clean metadata\n",
    "def clean_metadata(metadata):\n",
    "    return {\n",
    "        k.replace(\".\", \"_\").replace(\"-\", \"_\"): v\n",
    "        for k, v in metadata.items()\n",
    "    }\n",
    "\n",
    "for doc in split_documents:\n",
    "    doc.metadata = clean_metadata(doc.metadata)\n",
    "\n",
    "# 4. Embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "# 5. Milvus config\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"\",\n",
    "        \"token\": os.getenv(\"MILVUS_API_KEY\")\n",
    "    },\n",
    "    collection_name=\"my_pdf_docs\",\n",
    "    index_params={\"index_type\": \"HNSW\", \"metric_type\": \"L2\"},\n",
    "    search_params={\"ef\": 128},  \n",
    "    auto_id=True\n",
    ")\n",
    "\n",
    "# 6. Store\n",
    "texts = [doc.page_content for doc in split_documents]\n",
    "metadatas = [doc.metadata for doc in split_documents]\n",
    "ids = [str(uuid.uuid4()) for _ in texts]\n",
    "\n",
    "vector_store.add_texts(texts=texts, metadatas=metadatas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5812b505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '1706.03762v7.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'pk': 459601663938464695}, page_content='Convolu-\\ntional sequence to sequence learning.\\n\\narXiv preprint arXiv:1705.03122v2, 2017.\\n\\n[10] Alex Graves.\\n\\nGenerating sequences with recurrent neural networks.\\n\\narXiv preprint\\narXiv:1308.0850, 2013.\\n\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\\n\\nDeep residual learning for im-\\nage recognition.\\n\\nIn Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber.\\n\\nGradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n\\n[13] Sepp Hochreiter and Jürgen Schmidhuber.\\n\\nLong short-term memory.\\n\\nNeural computation,\\n9(8):1735–1780, 1997.\\n\\n[14] Zhongqiang Huang and Mary Harper.\\n\\nSelf-training PCFG grammars with latent annotations\\nacross languages.\\n\\nIn Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841.\\n\\nACL, August 2009.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '1706.03762v7.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'pk': 459601663938464653}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\n\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗ †\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder.\\n\\nThe best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism.\\n\\nWe propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '1706.03762v7.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'pk': 459601663938464698}, page_content='arXiv preprint arXiv:1511.06114, 2015.\\n\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning.\\n\\nEffective approaches to attention-\\nbased neural machine translation.\\n\\narXiv preprint arXiv:1508.04025, 2015.\\n\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '1706.03762v7.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'pk': 459601663938464655}, page_content='∗Equal contribution.\\n\\nListing order is random.\\n\\nJakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea.\\n\\nAshish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work.\\n\\nNoam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail.\\n\\nNiki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor.\\n\\nLlion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations.\\n\\nLukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n\\n†Work performed while at Google Brain.\\n\\n‡Work performed while at Google Research.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"who is the author?\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cb43dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5782b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-rag (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
